{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:54.140547Z",
     "start_time": "2024-03-12T16:05:54.133620800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "file_name = '../data/demo-4.csv'\n",
    "file_name_bmms = '../data/BMMS_overview.xlsx'\n",
    "file_name_roads = '../data/_roads3.csv'\n",
    "demo = pd.read_csv(file_name)\n",
    "bmms = pd.read_excel(file_name_bmms)\n",
    "roads = pd.read_csv(file_name_roads)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:57.796798300Z",
     "start_time": "2024-03-12T16:05:54.279172200Z"
    }
   },
   "id": "10281580ac8411a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Roads required: N1 N105 N102 N120 N104 N2 N204 N207 N208"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1da3a11c3934e9fe"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def clean_file(roads, bmms, road_name):\n",
    "    # Filter the 'roads' DataFrame for rows where the 'road' column is 'N1'\n",
    "    n1_roads = roads[roads['road'] == road_name]\n",
    "    n1_roads = n1_roads[(n1_roads['lon'] <= 91.851) &\n",
    "                     (n1_roads['lat'] >= 22.36)]\n",
    "    \n",
    "    # Generate an ID sequence starting from 1\n",
    "    n1_roads['id'] = range(1, len(n1_roads) + 1)\n",
    "    \n",
    "    # Set model_type to 'link' for all rows\n",
    "    n1_roads['model_type'] = 'link'\n",
    "    \n",
    "    # Generate 'name' as \"Link\" + id as string\n",
    "    #n1_roads['name'] = ['Link ' + str(id) for id in n1_roads['id']]\n",
    "    n1_roads['name'] = 'Link'\n",
    "    # Calculate 'length' as difference between this row's 'chainage' and the next row's 'chainage'\n",
    "    # Shift(-1) moves the chainage up by one row to subtract, fillna(0) to handle the last item\n",
    "    n1_roads['length'] = (n1_roads['chainage'].shift(-1) - n1_roads['chainage']).fillna(0)\n",
    "    \n",
    "    # Selecting the columns needed for the empty DataFrame\n",
    "    n1_roads_final = n1_roads[['road', 'id', 'model_type', 'name', 'lat', 'lon', 'length', 'chainage']]\n",
    "    \n",
    "    # Filter BMMS data for road 'N1'\n",
    "    bmms_n1 = bmms[bmms['road'] == road_name].copy()\n",
    "    bmms_n1 = bmms_n1[(bmms_n1['lon'] <= 91.851) &\n",
    "                     (bmms_n1['lat'] >= 22.363)]\n",
    "    \n",
    "    bmms_n1 = bmms_n1[~bmms_n1['name'].str.contains(r\"\\(R\\)\", na=False)]\n",
    "    bmms_n1 = bmms_n1[~bmms_n1['name'].str.contains(\"right\", case=False, na=False)]\n",
    "    bmms_n1 = bmms_n1[~bmms_n1['name'].str.contains(\"RIGHT\", case=False, na=False)]\n",
    "    bmms_n1 = bmms_n1[~bmms_n1['name'].str.contains(r\"\\( R \\)\", na=False)]\n",
    "    \n",
    "    # Set up for new entries\n",
    "    bmms_n1['model_type'] = 'bridge'\n",
    "    #bmms_n1['name'] = ['Bridge ' + str(i+1) for i in range(bmms_n1.shape[0])]\n",
    "    bmms_n1['id'] = range(n1_roads_final['id'].max() + 1, n1_roads_final['id'].max() + 1 + bmms_n1.shape[0])\n",
    "    bmms_n1['chainage'] = bmms_n1['km']  # Use 'km' as 'chainage'\n",
    "    bmms_n1['length'] = bmms_n1['length'] / 1000\n",
    "    \n",
    "    # Select and rename columns to match the format of n1_roads_final_with_chainage\n",
    "    bmms_n1_formatted = bmms_n1[['road', 'id', 'model_type', 'name', 'lat', 'lon', 'chainage', 'length', 'condition']]\n",
    "    \n",
    "    # Combine the dataframes and sort by chainage\n",
    "    combined_df = pd.concat([n1_roads_final, bmms_n1_formatted], ignore_index=True).sort_values(by='chainage')\n",
    "    \n",
    "    combined_df.iloc[0, 2] = 'source'\n",
    "    combined_df.iloc[-1, combined_df.columns.get_loc('model_type')] = 'sink'\n",
    "    combined_df.reset_index(drop=True, inplace=True)\n",
    "    count = 1\n",
    "    for index, row in combined_df.iterrows():\n",
    "        combined_df.iloc[index, 1] = count\n",
    "        count += 1\n",
    "    \n",
    "    n1 = combined_df\n",
    "    \n",
    "    duplicates_df = bmms_n1[bmms_n1.duplicated('km', keep=False)]\n",
    "\n",
    "    # Assuming duplicates_df is your DataFrame\n",
    "\n",
    "\n",
    "    # Convert 'condition' to a numerical value for averaging\n",
    "    condition_mapping = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5}\n",
    "    n1['condition_num'] = n1['condition'].map(condition_mapping)\n",
    "    \n",
    "    #add together the links\n",
    "    amount = 0\n",
    "    condition_sum = 0\n",
    "    rows_to_add = []  # List to accumulate rows\n",
    "    last_row = None\n",
    "    \n",
    "    # Initialize the DataFrame\n",
    "    n1_new = pd.DataFrame(columns=['road', \"id\", 'model_type', 'name', 'lon', 'lat', 'length', 'condition', 'condition_num'])\n",
    "    for index, row in n1.iterrows():\n",
    "        if last_row is not None:\n",
    "            if row['model_type'] == 'bridge':\n",
    "                amount += 1\n",
    "                condition_sum += row['condition_num']\n",
    "            if row['model_type'] != 'bridge' and last_row['model_type'] != 'bridge':\n",
    "                rows_to_add.append({'road': row['road'], 'id': row['id'], 'model_type': row['model_type'],\n",
    "                                    'name': row['name'],'lon': row['lon'], 'lat':row['lat'], 'length': row['length'], 'condition': row['condition'],\n",
    "                                    'condition_num': row['condition_num']})\n",
    "                amount = 0\n",
    "                condition_sum = 0\n",
    "            if row['model_type'] != 'bridge' and last_row['model_type'] == 'bridge':\n",
    "                rows_to_add.append({'road': last_row['road'], 'id': last_row['id'], 'model_type': last_row['model_type'],\n",
    "                                    'name': last_row['name'],'lon': row['lon'], 'lat':row['lat'], 'length': last_row['length'],\n",
    "                                    'condition': last_row['condition'], 'condition_num': condition_sum / amount})\n",
    "                amount = 0\n",
    "                condition_sum = 0\n",
    "                rows_to_add.append({'road': row['road'], 'id': row['id'], 'model_type': row['model_type'],\n",
    "                                    'name': row['name'],'lon': row['lon'], 'lat':row['lat'], 'length': row['length'], 'condition': row['condition'],\n",
    "                                    'condition_num': row['condition_num']})\n",
    "        else:\n",
    "            rows_to_add.append({'road': row['road'], 'id': row['id'], 'model_type': row['model_type'],\n",
    "                                'name': row['name'],'lon': row['lon'], 'lat':row['lat'], 'length': row['length'], 'condition': row['condition'],\n",
    "                                'condition_num': row['condition_num']})\n",
    "        last_row = row\n",
    "    \n",
    "    n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "\n",
    "    for index, row in n1_new.iterrows():\n",
    "        if pd.isna(row['condition_num']) == False:\n",
    "            n1_new.iloc[index, 8] = math.ceil(n1_new.iloc[index, 8])\n",
    "    condition_mapping = {1: 'A', 2: 'B', 3: 'C', 4: 'D', 5: 'E'}\n",
    "    n1_new['condition'] = n1_new['condition_num'].map(condition_mapping)\n",
    "    # n1_new\n",
    "    # n1_new['id'] = range(1, len(n1_new) + 1)\n",
    "    # for index, row in n1_new.iterrows():\n",
    "    #     if row['model_type'] != 'bridge':\n",
    "    #         n1_new.iloc[index, 3] = row['model_type'] + ' ' + str(row['id'])\n",
    "    #     else:\n",
    "    #         n1_new.iloc[index, 3] = n1_new.iloc[index, 3] + ' ' + str(row['id'])\n",
    "    # print(n1_new)\n",
    "    return n1_new"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T16:11:11.300338500Z",
     "start_time": "2024-03-12T16:11:11.290301800Z"
    }
   },
   "id": "339c46ec28a76cff"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
      "C:\\Users\\svenk\\AppData\\Local\\Temp\\ipykernel_14100\\598167041.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  n1_new = pd.concat([n1_new, pd.DataFrame(rows_to_add)], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "all_roads = []\n",
    "for road in ['N1', 'N105', 'N102', 'N120', 'N104', 'N2', 'N204', 'N207', 'N208']:\n",
    "    all_roads.append(clean_file(roads, bmms, road))\n",
    "merged_dataframe = pd.concat(all_roads, ignore_index=True)\n",
    "desired_order = ['road', 'id', 'model_type', 'condition', 'name', 'lat', 'lon', 'length']\n",
    "merged_dataframe = merged_dataframe[desired_order]\n",
    "count = 1\n",
    "for index, row in merged_dataframe.iterrows():\n",
    "    merged_dataframe.loc[index, 'id'] = str(count)\n",
    "    count+=1\n",
    "    if row.model_type == 'link':\n",
    "        merged_dataframe.loc[index, 'name'] = 'link ' + merged_dataframe.loc[index, 'id']\n",
    "    elif row.model_type == 'source':\n",
    "        merged_dataframe.loc[index, 'name'] = 'source ' + merged_dataframe.loc[index, 'id']\n",
    "    elif row.model_type == 'sink':\n",
    "        merged_dataframe.loc[index, 'name'] = 'sink ' + merged_dataframe.loc[index, 'id']\n",
    "    elif row.model_type == 'bridge':\n",
    "        merged_dataframe.loc[index, 'name'] = merged_dataframe.loc[index, 'name'] + ' id ' + merged_dataframe.loc[index, 'id']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T16:13:59.697550900Z",
     "start_time": "2024-03-12T16:13:58.104242900Z"
    }
   },
   "id": "338cd5991da5aca8"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "      road    id model_type condition                              name  \\\n0       N1     1     source       NaN                          source 1   \n1       N1     2       link       NaN                            link 2   \n2       N1     3       link       NaN                            link 3   \n3       N1     4       link       NaN                            link 4   \n4       N1     5     bridge         A                            . id 5   \n...    ...   ...        ...       ...                               ...   \n2876  N208  2877     bridge         A       Chatura Box Culvert id 2877   \n2877  N208  2878       link       NaN                         link 2878   \n2878  N208  2879       link       NaN                         link 2879   \n2879  N208  2880     bridge         A  GOBINDO PATI BOX CULVERT id 2880   \n2880  N208  2881       sink       NaN                         sink 2881   \n\n            lat        lon  length  \n0     23.706028  90.443333  0.8140  \n1     23.702917  90.450417  0.0080  \n2     23.702778  90.450472  0.1780  \n3     23.702139  90.451972  1.0000  \n4     23.697889  90.460583  0.0113  \n...         ...        ...     ...  \n2876  24.513472  91.843194  0.0016  \n2877  24.513472  91.843194  0.1620  \n2878  24.514250  91.844472  0.3660  \n2879  24.516028  91.847500  0.0124  \n2880  24.516028  91.847500  0.0000  \n\n[2881 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>road</th>\n      <th>id</th>\n      <th>model_type</th>\n      <th>condition</th>\n      <th>name</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>N1</td>\n      <td>1</td>\n      <td>source</td>\n      <td>NaN</td>\n      <td>source 1</td>\n      <td>23.706028</td>\n      <td>90.443333</td>\n      <td>0.8140</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>N1</td>\n      <td>2</td>\n      <td>link</td>\n      <td>NaN</td>\n      <td>link 2</td>\n      <td>23.702917</td>\n      <td>90.450417</td>\n      <td>0.0080</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>N1</td>\n      <td>3</td>\n      <td>link</td>\n      <td>NaN</td>\n      <td>link 3</td>\n      <td>23.702778</td>\n      <td>90.450472</td>\n      <td>0.1780</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>N1</td>\n      <td>4</td>\n      <td>link</td>\n      <td>NaN</td>\n      <td>link 4</td>\n      <td>23.702139</td>\n      <td>90.451972</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>N1</td>\n      <td>5</td>\n      <td>bridge</td>\n      <td>A</td>\n      <td>. id 5</td>\n      <td>23.697889</td>\n      <td>90.460583</td>\n      <td>0.0113</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2876</th>\n      <td>N208</td>\n      <td>2877</td>\n      <td>bridge</td>\n      <td>A</td>\n      <td>Chatura Box Culvert id 2877</td>\n      <td>24.513472</td>\n      <td>91.843194</td>\n      <td>0.0016</td>\n    </tr>\n    <tr>\n      <th>2877</th>\n      <td>N208</td>\n      <td>2878</td>\n      <td>link</td>\n      <td>NaN</td>\n      <td>link 2878</td>\n      <td>24.513472</td>\n      <td>91.843194</td>\n      <td>0.1620</td>\n    </tr>\n    <tr>\n      <th>2878</th>\n      <td>N208</td>\n      <td>2879</td>\n      <td>link</td>\n      <td>NaN</td>\n      <td>link 2879</td>\n      <td>24.514250</td>\n      <td>91.844472</td>\n      <td>0.3660</td>\n    </tr>\n    <tr>\n      <th>2879</th>\n      <td>N208</td>\n      <td>2880</td>\n      <td>bridge</td>\n      <td>A</td>\n      <td>GOBINDO PATI BOX CULVERT id 2880</td>\n      <td>24.516028</td>\n      <td>91.847500</td>\n      <td>0.0124</td>\n    </tr>\n    <tr>\n      <th>2880</th>\n      <td>N208</td>\n      <td>2881</td>\n      <td>sink</td>\n      <td>NaN</td>\n      <td>sink 2881</td>\n      <td>24.516028</td>\n      <td>91.847500</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2881 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T16:13:59.716082500Z",
     "start_time": "2024-03-12T16:13:59.697550900Z"
    }
   },
   "id": "c4ea20dc6aeeb9f1"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "merged_dataframe.to_csv('../data/merged_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T16:14:19.468969500Z",
     "start_time": "2024-03-12T16:14:19.448692800Z"
    }
   },
   "id": "8701773f1577f29a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T16:01:58.766559900Z",
     "start_time": "2024-03-12T16:01:58.750229500Z"
    }
   },
   "id": "8cf515a044afec8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9470c895a7adf1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
