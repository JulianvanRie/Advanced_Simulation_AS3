{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:04:14.324347100Z",
     "start_time": "2024-04-03T11:04:14.309099900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "folder_path = '../data/Traffic_data'\n",
    "dataframes = {}\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.traffic.htm'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        file_name = file.split('.')[0]\n",
    "        df_list = pd.read_html(file_path)\n",
    "        df = df_list[4]\n",
    "        df = df.iloc[1:].reset_index(drop=True)\n",
    "        df_key = file_name\n",
    "        dataframes[df_key] = df\n",
    "# Create an empty list to store the modified DataFrames\n",
    "modified_dfs = []\n",
    "\n",
    "# Iterate through the dictionary and skip the first two rows of each DataFrame\n",
    "for key, df in dataframes.items():\n",
    "    modified_df = df.iloc[2:]  # Skip the first two rows\n",
    "    modified_dfs.append(modified_df)\n",
    "\n",
    "# Concatenate all the modified DataFrames into one big DataFrame\n",
    "big_df = pd.concat(modified_dfs, ignore_index=True)\n",
    "columns = df.iloc[1].tolist()\n",
    "columns[5] = \"LRP_2\"\n",
    "columns[6] = \"Offset_2\"\n",
    "columns[7] = \"Chainage_2\"\n",
    "columns[0] = 'Road'\n",
    "columns[1] = 'Name'\n",
    "big_df.columns = columns\n",
    "big_df['type'] = 'road'\n",
    "\n",
    "\n",
    "# Define a function to find all road names in the 'Name' column\n",
    "def find_roads(name):\n",
    "    # Regular expression to match the pattern described (roads starting with Z, N, or R followed by numbers)\n",
    "    road_pattern = re.compile(r'\\b[nNzZrR]\\d+\\b')\n",
    "    # Find all matches in the name\n",
    "    found_roads = road_pattern.findall(name)\n",
    "    return found_roads\n",
    "\n",
    "\n",
    "# Apply the function to the 'Name' column to create a new column with the list of identified roads\n",
    "big_df['identified_roads'] = big_df['Name'].apply(find_roads)\n",
    "\n",
    "bmms = pd.read_excel(\"../data/BMMS_overview.xlsx\")\n",
    "big_df['base_road'] = big_df['Road'].apply(lambda x: x.split('-')[0])\n",
    "big_df['Chainage'] = pd.to_numeric(big_df['Chainage'], errors='coerce')\n",
    "bmms['chainage'] = pd.to_numeric(bmms['chainage'], errors='coerce')\n",
    "\n",
    "bmms_subset = bmms[['road', 'chainage', 'name', 'condition', 'lat', 'lon']].copy()\n",
    "bmms_subset.rename(columns={'road': 'base_road', 'chainage': 'Chainage', 'name': 'Name'}, inplace=True)\n",
    "\n",
    "for col in big_df.columns:\n",
    "    if col not in bmms_subset.columns:\n",
    "        bmms_subset[col] = pd.NA\n",
    "bmms_subset['type'] = 'bridge'\n",
    "\n",
    "combined_df = pd.concat([big_df, bmms_subset], ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.sort_values(by=['base_road', 'Chainage'])\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "combined_df\n",
    "roads = pd.read_csv('../../EPA133a-G2-A3/data/_roads3.csv')\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "    if pd.isnull(row['lat']):\n",
    "        chainage = row['Chainage']\n",
    "        road = row['base_road']\n",
    "        closest_chainage = 9999\n",
    "        closest_lat = 99999\n",
    "        closest_lon = 99999\n",
    "        closest_row = None\n",
    "        for index2, row2 in roads[roads['road'] == road].iterrows():\n",
    "            if abs(chainage - row2['chainage']) < closest_chainage:\n",
    "                closest_row = row2\n",
    "                closest_lat = row2['lat']\n",
    "                closest_lon = row2['lon']\n",
    "                closest_chainage = abs(chainage - row2['chainage'])\n",
    "            else:\n",
    "                combined_df.loc[index, 'lat'] = closest_lat\n",
    "                combined_df.loc[index, 'lon'] = closest_lon\n",
    "                break\n",
    "\n",
    "combined_df.to_csv('../data/traffic_df_with_bridges.csv', index=False)\n",
    "df = combined_df.copy()\n",
    "df_filtered = df[~df[\"Road\"].str.contains(\"L\", na=False)]\n",
    "df_filtered.to_csv('../data/cleaned_df_A4.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:05:51.912396600Z",
     "start_time": "2024-04-03T11:04:34.581306300Z"
    }
   },
   "id": "34f5b4ce21675ed1",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
